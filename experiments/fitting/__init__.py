import math

from enf import EquivariantCrossAttentionENF
from enf.steerable_attention.invariant import get_sa_invariant, get_ca_invariant
from enf.latents.autodecoder import PositionOrientationFeatureAutodecoder
from enf.latents.autodecoder import PositionOrientationFeatureAutodecoderMeta


def get_model(cfg):
    """ Get autodecoders and snef based on the configuration. """

    # Determine whether we are doing meta-learning
    if "meta" not in cfg:
        # Init invariant
        self_attn_invariant = get_sa_invariant(cfg.nef)
        cross_attn_invariant = get_ca_invariant(cfg.nef)

        # Calculate initial gaussian window size
        assert math.sqrt(cfg.nef.num_latents)

        # Init autodecoder
        train_autodecoder = PositionOrientationFeatureAutodecoder(
            num_signals=cfg.dataset.num_signals_train,
            num_latents=cfg.nef.num_latents,
            latent_dim=cfg.nef.latent_dim,
            num_pos_dims=cross_attn_invariant.num_z_pos_dims,
            num_ori_dims=cross_attn_invariant.num_z_ori_dims,
            gaussian_window_size=cfg.nef.gaussian_window,
        )

        val_autodecoder = PositionOrientationFeatureAutodecoder(
            num_signals=cfg.dataset.num_signals_test,
            num_latents=cfg.nef.num_latents,
            latent_dim=cfg.nef.latent_dim,
            num_pos_dims=cross_attn_invariant.num_z_pos_dims,
            num_ori_dims=cross_attn_invariant.num_z_ori_dims,
            gaussian_window_size=cfg.nef.gaussian_window,
        )

        # Init model
        enf = EquivariantCrossAttentionENF(
            num_hidden=cfg.nef.num_hidden,
            num_heads=cfg.nef.num_heads,
            num_self_att_layers=cfg.nef.num_self_att_layers,
            num_out=cfg.nef.num_out,
            latent_dim=cfg.nef.latent_dim,
            self_attn_invariant=self_attn_invariant,
            cross_attn_invariant=cross_attn_invariant,
            embedding_type=cfg.nef.embedding_type,
            embedding_freq_multiplier=[cfg.nef.embedding_freq_multiplier_invariant,
                                       cfg.nef.embedding_freq_multiplier_value],
            condition_value_transform=cfg.nef.condition_value_transform,
            top_k_latent_sampling=cfg.nef.top_k,
        )
        return enf, train_autodecoder, val_autodecoder
    else:

        # Init invariant
        self_attn_invariant = get_sa_invariant(cfg.nef) # è¿”å›çš„å¯¹è±¡å°±æ˜¯å¯¹è¾“å…¥åæ ‡/å§¿æ€åšç›¸åº”çš„â€œç­‰å˜æˆ–ä¸å˜â€ç‰¹å¾å˜æ¢çš„å‡½æ•°
        cross_attn_invariant = get_ca_invariant(cfg.nef) # è¿”å›çš„å…·ä½“æ˜¯ï¼š BaseInvariant: The invariant module.

        # Calculate initial gaussian window size
        assert math.sqrt(cfg.nef.num_latents)

        # Init autodecoder
        # TODO:è¿™é‡Œçš„ä¸¤ä¸ªdecoderåˆ°åº•æ˜¯éƒ½åœ¨å†…å¾ªç¯ä¸­ç”¨äºåˆ†åˆ«è·å–éšå˜é‡è¡¨è¾¾çš„å±€éƒ¨å’Œå…¨å±€å½¢å¼ï¼Ÿè¿˜æ˜¯outerdecoderå°±å·²ç»ç”¨åœ¨å¤–å¾ªç¯ä¸­å¯èƒ½è¢«æ›´æ–°çš„ä¸€ç»„å…¨å±€æ½œå˜é‡ï¼Ÿ
        inner_autodecoder = PositionOrientationFeatureAutodecoderMeta( # é€šå¸¸å°±æ˜¯ä¸å½“å‰ä»»åŠ¡/ä¿¡å·å…³è”çš„éšå˜é‡ğ‘§
            num_signals=cfg.dataset.batch_size,
            # Since we're doing meta-learning, the inner and val autodecoders have batch_size as num signals
            num_latents=cfg.nef.num_latents,
            latent_dim=cfg.nef.latent_dim,
            num_pos_dims=cross_attn_invariant.num_z_pos_dims,
            num_ori_dims=cross_attn_invariant.num_z_ori_dims,
            gaussian_window_size=cfg.nef.gaussian_window,
        )
        # num_signals=1 è¡¨ç¤ºå®ƒåªç»´æŠ¤â€œä¸€å¥—æ½œå˜é‡â€â€”â€”å¾€å¾€å°±æ˜¯å…¨å±€å…±äº«ã€è·¨æ‰€æœ‰ä»»åŠ¡éƒ½è¦ç”¨åˆ°æˆ–å­¦ä¹ çš„é‚£éƒ¨åˆ†ã€‚
        # åœ¨å¤–å¾ªç¯ä¸­ï¼Œå®ƒå’Œ ENF çš„å‚æ•° ğœƒä¸€èµ·æ›´æ–°ï¼Œæ‰®æ¼”äº†â€œè·¨ä»»åŠ¡å…±äº«å…ˆéªŒâ€æˆ–â€œå¤–å±‚å…¨å±€æ½œå˜é‡â€ çš„è§’è‰²ã€‚
        # å®ƒå¹¶ä¸ä¼šåœ¨å†…å¾ªç¯é‡Œç”Ÿæˆæ–°çš„ zï¼Œä¹Ÿä¸å‚ä¸å¯¹æ¯æ¡æ•°æ®/æ¯ä¸ªä»»åŠ¡çš„å±€éƒ¨é€‚é…ï¼›è€Œæ˜¯å’Œ ğœƒä¸€æ ·ï¼Œéšç€å¤–å¾ªç¯çš„æ¢¯åº¦ä¸€èµ·è¢«æ›´æ–°ã€‚ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ
        outer_autodecoder = PositionOrientationFeatureAutodecoderMeta(
            num_signals=1,  # Since we're doing meta-learning, we only optimize one set of latents
            num_latents=cfg.nef.num_latents,
            latent_dim=cfg.nef.latent_dim,
            num_pos_dims=cross_attn_invariant.num_z_pos_dims,
            num_ori_dims=cross_attn_invariant.num_z_ori_dims,
            gaussian_window_size=cfg.nef.gaussian_window,
        )

        # Init model
        enf = EquivariantCrossAttentionENF(
            num_hidden=cfg.nef.num_hidden,
            num_heads=cfg.nef.num_heads,
            num_self_att_layers=cfg.nef.num_self_att_layers,
            num_out=cfg.nef.num_out,
            latent_dim=cfg.nef.latent_dim,
            self_attn_invariant=self_attn_invariant, # ä½¿ç½‘ç»œåœ¨æ‰§è¡Œæ³¨æ„åŠ›æ“ä½œæ—¶ï¼Œè‡ªåŠ¨å¯¹åæ ‡ã€å§¿æ€ã€æ¡ä»¶è¿›è¡Œæ­£ç¡®çš„ç­‰å˜/ä¸å˜å¤„ç†ï¼›æ¢å¥è¯è¯´ï¼Œæ¯æ¬¡ç½‘ç»œå‰å‘ä¸­
            cross_attn_invariant=cross_attn_invariant, # ä¼ å…¥çš„(x,p,c)ä¼šå…ˆé€šè¿‡invariantå‡½æ•°å¾—åˆ°ä¸å˜è¡¨ç¤ºï¼Œç„¶åå†è¿›å…¥q,k,vï¼Œä»è€Œä¿è¯äº†ç½‘ç»œç¾¤ä½œç”¨çš„ç­‰å˜æ€§
            embedding_type=cfg.nef.embedding_type,
            embedding_freq_multiplier=[cfg.nef.embedding_freq_multiplier_invariant,
                                       cfg.nef.embedding_freq_multiplier_value],
            condition_value_transform=cfg.nef.condition_value_transform,
            top_k_latent_sampling=cfg.nef.top_k,
        )
        return enf, inner_autodecoder, outer_autodecoder
